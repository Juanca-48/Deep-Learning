# -*- coding: utf-8 -*-
"""HW5 modelo fusionado y secuencial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s3Ciyf9k8LB-HXSlgVjI2g05CqRKdv5q

# HW4 — Fusión MobileNetV2 + VGG16 (FIX estratificación HF + NumPy 2.0)

## 1) Instalación de dependencias
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip -q install -U datasets==2.19.0 huggingface_hub==0.24.6
# !pip -q install -U scikit-learn==1.5.2

"""## 2) Carga de librerías"""

import os, random, numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from google.colab import files
from PIL import Image
import io

from datasets import load_dataset
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import f1_score, confusion_matrix, classification_report

# Keras / modelo
from tensorflow.keras import Model, Input
from tensorflow.keras.layers import (Lambda, GlobalAveragePooling2D, Concatenate,
                                     Dense, Dropout)
from tensorflow.keras.applications import MobileNetV2, VGG16
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess

"""## 3) Hiperparámetros y utilidades"""

SEED = 42
tf.random.set_seed(SEED); np.random.seed(SEED); random.seed(SEED)

IMG_SIZE = 224
NUM_CLASSES = 10
BATCH_SIZE = 32
EPOCHS_FROZEN = 8
EPOCHS_FINETUNE = 6
LR_BASE = 1e-3
LR_FINETUNE = 1e-4
AUTOTUNE = tf.data.AUTOTUNE

print("TensorFlow:", tf.__version__)

"""## 4) Carga directa del dataset y **partición estratificada con scikit-learn**


"""

# 4.1 Cargar dataset (requiere conexión)
ds_all = load_dataset("Bingsu/Gameplay_Images")
base = ds_all["train"]
label_names = base.features["label"].names
labels = base["label"]  # lista python
idx = np.arange(len(labels))

# 4.2 80/20 -> trainval/test (estratificado)
sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)
trainval_idx, test_idx = next(sss1.split(idx, labels))

ds_trainval = base.select(trainval_idx)
ds_test = base.select(test_idx)

# 4.3 80/20 de trainval -> train/val (equivalente a 64/16 global)
labels_trainval = [labels[i] for i in trainval_idx]
sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)
train_rel, val_rel = next(sss2.split(np.arange(len(trainval_idx)), labels_trainval))
train_idx = [trainval_idx[i] for i in train_rel]
val_idx   = [trainval_idx[i] for i in val_rel]

hf_train = base.select(train_idx)
hf_val   = base.select(val_idx)
hf_test  = ds_test

print("Clases:", label_names)
print("Tamaños -> train:", len(hf_train), "val:", len(hf_val), "test:", len(hf_test))

"""## 5) Redimensionamiento a 224×224 y creación de `tf.data`"""

def _resize_batch(batch):
    imgs = []
    for img in batch["image"]:
        img = img.convert("RGB").resize((IMG_SIZE, IMG_SIZE))
        imgs.append(np.array(img))
    return {"image": imgs, "label": batch["label"]}

hf_train = hf_train.with_transform(_resize_batch)
hf_val   = hf_val.with_transform(_resize_batch)
hf_test  = hf_test.with_transform(_resize_batch)

def make_tf_dataset(hf_ds, shuffle, batch_size=BATCH_SIZE):
    # Modify to return a tuple structure directly
    ds = hf_ds.to_tf_dataset(columns="image", label_cols="label", # Changed to single strings
                             shuffle=shuffle, batch_size=batch_size)
    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32), # x is now the image tensor
                              tf.one_hot(y, depth=NUM_CLASSES)),
                num_parallel_calls=AUTOTUNE)
    return ds.prefetch(AUTOTUNE)

train_ds = make_tf_dataset(hf_train, shuffle=True)
val_ds   = make_tf_dataset(hf_val, shuffle=False)
test_ds  = make_tf_dataset(hf_test, shuffle=False)

xb, yb = next(iter(train_ds))
print("Batch X:", xb.shape, xb.dtype, "| Batch y:", yb.shape, yb.dtype)

"""## 6) Modelo de fusión MobileNetV2 + VGG16"""

def build_fusion_model(img_size=IMG_SIZE, num_classes=NUM_CLASSES, freeze_backbones=True):
    inputs = Input(shape=(img_size, img_size, 3), name="input_image")
    x_m = Lambda(mobilenet_preprocess, name="mobilenet_preprocess")(inputs)
    x_v = Lambda(vgg_preprocess,       name="vgg_preprocess")(inputs)

    base_m = MobileNetV2(weights="imagenet", include_top=False, input_tensor=x_m)
    base_v = VGG16(weights="imagenet",      include_top=False, input_tensor=x_v)

    if freeze_backbones:
        for layer in base_m.layers: layer.trainable = False
        for layer in base_v.layers: layer.trainable = False

    feat_m = GlobalAveragePooling2D(name="gap_mobilenet")(base_m.output)
    feat_v = GlobalAveragePooling2D(name="gap_vgg")(base_v.output)
    fused = Concatenate(name="concat_features")([feat_m, feat_v])

    x = Dense(512, activation="relu", name="dense_512")(fused)
    x = Dropout(0.3, name="dropout_0_3")(x)
    outputs = Dense(num_classes, activation="softmax", name="predictions")(x)
    model = Model(inputs=inputs, outputs=outputs, name="Fusion_MobileNetV2_VGG16")
    return model, base_m, base_v

model, base_m, base_v = build_fusion_model()
model.summary(line_length=120)

"""## 7) Entrenamiento Fase 1 (backbones congelados)"""

optimizer = tf.keras.optimizers.Adam(learning_rate=LR_BASE)
model.compile(optimizer=optimizer, loss="categorical_crossentropy",
              metrics=[tf.keras.metrics.CategoricalAccuracy(name="categorical_accuracy")])

history_frozen = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FROZEN)

"""## 8) Curvas de entrenamiento (Fase 1)"""

# Loss
plt.figure()
plt.plot(history_frozen.history['loss'], label='train')
plt.plot(history_frozen.history['val_loss'], label='val')
plt.title('Loss (Fase 1)'); plt.xlabel('Época'); plt.ylabel('Loss'); plt.legend(); plt.show()

# Accuracy
plt.figure()
plt.plot(history_frozen.history['categorical_accuracy'], label='train')
plt.plot(history_frozen.history['val_categorical_accuracy'], label='val')
plt.title('Accuracy (Fase 1)'); plt.xlabel('Época'); plt.ylabel('Accuracy'); plt.legend(); plt.show()

"""## 9) Fine-tuning (descongelar parcialmente + LR menor)"""

for layer in base_m.layers[-20:]: layer.trainable = True
for layer in base_v.layers[-4:]:  layer.trainable = True

optimizer_ft = tf.keras.optimizers.Adam(learning_rate=LR_FINETUNE)
model.compile(optimizer=optimizer_ft, loss="categorical_crossentropy",
              metrics=[tf.keras.metrics.CategoricalAccuracy(name="categorical_accuracy")])

history_ft = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FINETUNE)

"""## 10) Curvas de entrenamiento (Fase 2)"""

# Loss
plt.figure()
plt.plot(history_ft.history['loss'], label='train')
plt.plot(history_ft.history['val_loss'], label='val')
plt.title('Loss (Fase 2 - FT)'); plt.xlabel('Época'); plt.ylabel('Loss'); plt.legend(); plt.show()

# Accuracy
plt.figure()
plt.plot(history_ft.history['categorical_accuracy'], label='train')
plt.plot(history_ft.history['val_categorical_accuracy'], label='val')
plt.title('Accuracy (Fase 2 - FT)'); plt.xlabel('Época'); plt.ylabel('Accuracy'); plt.legend(); plt.show()

"""## 11) Evaluación en test: Top-1, Macro-F1 y matriz de confusión"""

eval_loss, eval_acc = model.evaluate(test_ds, verbose=0)
print(f"Test -> Loss: {eval_loss:.4f} | Accuracy: {eval_acc:.4f}")

y_true, y_pred = [], []
for xb, yb in test_ds:
    probs = model.predict(xb, verbose=0)
    y_true.extend(np.argmax(yb.numpy(), axis=1))
    y_pred.extend(np.argmax(probs, axis=1))

macro_f1 = f1_score(y_true, y_pred, average='macro')
print(f"Macro-F1: {macro_f1:.4f}\n")
print(classification_report(y_true, y_pred, target_names=label_names, digits=4))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,8))
plt.imshow(cm, interpolation='nearest')
plt.title('Matriz de confusión (test)'); plt.xlabel('Predicción'); plt.ylabel('Verdadero')
plt.colorbar(shrink=0.8)
ticks = np.arange(len(label_names))
plt.xticks(ticks, label_names, rotation=90); plt.yticks(ticks, label_names)
plt.tight_layout(); plt.show()

"""## 12) Predicción visual en una imagen aleatoria de test"""

# 1) Subir imagen(es)
uploaded = files.upload()  # selecciona una o varias imágenes desde tu equipo

# 2) Tomamos la primera imagen subida y la preprocesamos (solo resize a 224x224; el modelo aplica su propio preprocess)
for fname, file_bytes in uploaded.items():
    img = Image.open(io.BytesIO(file_bytes)).convert("RGB").resize((IMG_SIZE, IMG_SIZE))
    x_single = np.array(img, dtype=np.float32)              # rango [0..255]
    x_single = np.expand_dims(x_single, axis=0)             # (1, 224, 224, 3)

    # 3) Predicción
    probs = model.predict(x_single, verbose=0)[0]
    pred_idx = int(np.argmax(probs))
    pred_label = label_names[pred_idx]
    pred_conf = float(probs[pred_idx])

    # 4) Visualización
    plt.figure()
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Predicción: {pred_label}  (p={pred_conf:.3f})")
    plt.show()

"""## 13) Construcción del Modelo Secuencial (MobileNetV2 → VGG16)"""

def build_sequential_model(img_size=IMG_SIZE, num_classes=NUM_CLASSES, freeze_backbones=True):
    """
    Modelo secuencial donde:
    1. MobileNetV2 extrae características de la imagen original (224x224x3 -> 7x7x1280)
    2. Las características se procesan y redimensionan (upsampling) a 224x224x3
    3. VGG16 procesa esta "nueva imagen" generada desde las features de MobileNetV2
    4. Se combinan las salidas para la clasificación final
    """
    inputs = Input(shape=(img_size, img_size, 3), name="input_image")

    # Paso 1: MobileNetV2 procesa la imagen original
    x_m = Lambda(mobilenet_preprocess, name="mobilenet_preprocess")(inputs)
    base_m = MobileNetV2(weights="imagenet", include_top=False, input_tensor=x_m)

    if freeze_backbones:
        for layer in base_m.layers:
            layer.trainable = False

    # Extraer features de MobileNetV2 (7x7x1280)
    mobilenet_features = base_m.output

    # Paso 2: Transformar features de MobileNetV2 para crear una "imagen" para VGG16
    # 2.1: Reducir dimensionalidad de canales: 1280 -> 64
    x = tf.keras.layers.Conv2D(64, (1, 1), activation='relu',
                               name='reduce_channels', padding='same')(mobilenet_features)

    # 2.2: Upsampling progresivo de 7x7 a 224x224
    # 7x7 -> 14x14
    x = tf.keras.layers.UpSampling2D(size=(2, 2), name='upsample_1')(x)
    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu',
                               name='conv_up_1', padding='same')(x)

    # 14x14 -> 28x28
    x = tf.keras.layers.UpSampling2D(size=(2, 2), name='upsample_2')(x)
    x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu',
                               name='conv_up_2', padding='same')(x)

    # 28x28 -> 56x56
    x = tf.keras.layers.UpSampling2D(size=(2, 2), name='upsample_3')(x)
    x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu',
                               name='conv_up_3', padding='same')(x)

    # 56x56 -> 112x112
    x = tf.keras.layers.UpSampling2D(size=(2, 2), name='upsample_4')(x)
    x = tf.keras.layers.Conv2D(4, (3, 3), activation='relu',
                               name='conv_up_4', padding='same')(x)

    # 112x112 -> 224x224
    x = tf.keras.layers.UpSampling2D(size=(2, 2), name='upsample_5')(x)

    # 2.3: Convertir a 3 canales (RGB-like) para VGG16
    adapted_features = tf.keras.layers.Conv2D(3, (3, 3), activation='relu',
                                              name='to_rgb', padding='same')(x)

    # Paso 3: Preprocesar para VGG16 y pasar por VGG16
    # Crear VGG16 independiente (sin input_tensor)
    x_v = Lambda(vgg_preprocess, name="vgg_preprocess_sequential")(adapted_features)
    base_v = VGG16(weights="imagenet", include_top=False, input_shape=(img_size, img_size, 3))

    if freeze_backbones:
        for layer in base_v.layers:
            layer.trainable = False

    # Aplicar VGG16 a las features adaptadas
    vgg_output = base_v(x_v)

    # Paso 4: Combinar ambas salidas
    feat_m = GlobalAveragePooling2D(name="gap_mobilenet")(mobilenet_features)
    feat_v = GlobalAveragePooling2D(name="gap_vgg")(vgg_output)

    # Concatenar las características de ambas redes
    combined = Concatenate(name="concat_sequential")([feat_m, feat_v])

    # Capas densas finales
    x = Dense(512, activation="relu", name="dense_512_seq")(combined)
    x = Dropout(0.3, name="dropout_0_3_seq")(x)
    outputs = Dense(num_classes, activation="softmax", name="predictions_seq")(x)

    model = Model(inputs=inputs, outputs=outputs, name="Sequential_MobileNetV2_VGG16")
    return model, base_m, base_v

# Construir el modelo secuencial
model_seq, base_m_seq, base_v_seq = build_sequential_model()
model_seq.summary(line_length=120)

"""## 14) Entrenamiento Fase 1 - Modelo Secuencial (backbones congelados)"""

optimizer_seq = tf.keras.optimizers.Adam(learning_rate=LR_BASE)
model_seq.compile(
    optimizer=optimizer_seq,
    loss="categorical_crossentropy",
    metrics=[tf.keras.metrics.CategoricalAccuracy(name="categorical_accuracy")]
)

print("\n=== Entrenando Modelo Secuencial - Fase 1 (Backbones Congelados) ===\n")
history_frozen_seq = model_seq.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_FROZEN
)

"""## 15) Curvas de entrenamiento - Modelo Secuencial (Fase 1)"""

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history_frozen_seq.history['loss'], label='train', marker='o')
axes[0].plot(history_frozen_seq.history['val_loss'], label='val', marker='s')
axes[0].set_title('Loss - Modelo Secuencial (Fase 1)')
axes[0].set_xlabel('Época')
axes[0].set_ylabel('Loss')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Accuracy
axes[1].plot(history_frozen_seq.history['categorical_accuracy'], label='train', marker='o')
axes[1].plot(history_frozen_seq.history['val_categorical_accuracy'], label='val', marker='s')
axes[1].set_title('Accuracy - Modelo Secuencial (Fase 1)')
axes[1].set_xlabel('Época')
axes[1].set_ylabel('Accuracy')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

"""## 16) Fine-tuning - Modelo Secuencial (descongelar parcialmente + LR menor)"""

# Descongelar últimas capas
for layer in base_m_seq.layers[-20:]:
    layer.trainable = True
for layer in base_v_seq.layers[-4:]:
    layer.trainable = True

optimizer_ft_seq = tf.keras.optimizers.Adam(learning_rate=LR_FINETUNE)
model_seq.compile(
    optimizer=optimizer_ft_seq,
    loss="categorical_crossentropy",
    metrics=[tf.keras.metrics.CategoricalAccuracy(name="categorical_accuracy")]
)

print("\n=== Entrenando Modelo Secuencial - Fase 2 (Fine-tuning) ===\n")
history_ft_seq = model_seq.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_FINETUNE
)

"""## 17) Curvas de entrenamiento - Modelo Secuencial (Fase 2)"""

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Loss
axes[0].plot(history_ft_seq.history['loss'], label='train', marker='o')
axes[0].plot(history_ft_seq.history['val_loss'], label='val', marker='s')
axes[0].set_title('Loss - Modelo Secuencial (Fase 2 - FT)')
axes[0].set_xlabel('Época')
axes[0].set_ylabel('Loss')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Accuracy
axes[1].plot(history_ft_seq.history['categorical_accuracy'], label='train', marker='o')
axes[1].plot(history_ft_seq.history['val_categorical_accuracy'], label='val', marker='s')
axes[1].set_title('Accuracy - Modelo Secuencial (Fase 2 - FT)')
axes[1].set_xlabel('Época')
axes[1].set_ylabel('Accuracy')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

"""## 18) Evaluación en test - Modelo Secuencial"""

eval_loss_seq, eval_acc_seq = model_seq.evaluate(test_ds, verbose=0)
print(f"\n=== Modelo Secuencial - Resultados en Test ===")
print(f"Loss: {eval_loss_seq:.4f} | Accuracy: {eval_acc_seq:.4f}")

y_true_seq, y_pred_seq = [], []
for xb, yb in test_ds:
    probs = model_seq.predict(xb, verbose=0)
    y_true_seq.extend(np.argmax(yb.numpy(), axis=1))
    y_pred_seq.extend(np.argmax(probs, axis=1))

macro_f1_seq = f1_score(y_true_seq, y_pred_seq, average='macro')
print(f"Macro-F1: {macro_f1_seq:.4f}\n")
print(classification_report(y_true_seq, y_pred_seq, target_names=label_names, digits=4))

# Matriz de confusión
cm_seq = confusion_matrix(y_true_seq, y_pred_seq)
plt.figure(figsize=(8, 8))

# Crear colormap personalizado morado oscuro-amarillo (igual a la imagen)
from matplotlib.colors import LinearSegmentedColormap
colors = ['#3d1e52', '#FFEB3B']  # Morado oscuro a Amarillo brillante
n_bins = 100
cmap_custom = LinearSegmentedColormap.from_list('purple_yellow', colors, N=n_bins)

plt.imshow(cm_seq, interpolation='nearest', cmap=cmap_custom)
plt.title('Matriz de Confusión - Modelo Secuencial (test)')
plt.xlabel('Predicción')
plt.ylabel('Verdadero')
plt.colorbar(shrink=0.8)
ticks = np.arange(len(label_names))
plt.xticks(ticks, label_names, rotation=90)
plt.yticks(ticks, label_names)
plt.tight_layout()
plt.show()

"""## 19) COMPARATIVA: Modelo Fusión vs Modelo Secuencial"""

print("\n" + "="*70)
print("COMPARATIVA DE MODELOS")
print("="*70)

# Tabla comparativa
comparison_data = {
    'Métrica': ['Test Accuracy', 'Test Loss', 'Macro-F1'],
    'Modelo Fusión (Paralelo)': [
        f"{eval_acc:.4f}",
        f"{eval_loss:.4f}",
        f"{macro_f1:.4f}"
    ],
    'Modelo Secuencial': [
        f"{eval_acc_seq:.4f}",
        f"{eval_loss_seq:.4f}",
        f"{macro_f1_seq:.4f}"
    ]
}

import pandas as pd
df_comparison = pd.DataFrame(comparison_data)
print("\n", df_comparison.to_string(index=False))

# Gráfico comparativo
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

metrics = ['Accuracy', 'Loss', 'Macro-F1']
fusion_values = [eval_acc, eval_loss, macro_f1]
sequential_values = [eval_acc_seq, eval_loss_seq, macro_f1_seq]

for idx, (metric, fusion_val, seq_val) in enumerate(zip(metrics, fusion_values, sequential_values)):
    axes[idx].bar(['Fusión\n(Paralelo)', 'Secuencial'], [fusion_val, seq_val],
                  color=['#3498db', '#e74c3c'], alpha=0.7, edgecolor='black')
    axes[idx].set_title(f'{metric}')
    axes[idx].set_ylabel('Valor')
    axes[idx].grid(True, alpha=0.3, axis='y')

    # Añadir valores sobre las barras
    for i, v in enumerate([fusion_val, seq_val]):
        axes[idx].text(i, v + (0.01 if metric != 'Loss' else -0.02),
                      f'{v:.4f}', ha='center', va='bottom' if metric != 'Loss' else 'top',
                      fontweight='bold')

plt.suptitle('Comparación: Modelo Fusión vs Modelo Secuencial', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

print("\n" + "="*70)
print("ANÁLISIS:")
print("- Modelo Fusión: Procesa con ambas redes EN PARALELO")
print("- Modelo Secuencial: MobileNetV2 → adaptación → VGG16")
print("="*70)

"""## 20) Predicción en imagen individual - Modelo Secuencial"""

print("\n=== Predicción con Modelo Secuencial ===")
uploaded = files.upload()

for fname, file_bytes in uploaded.items():
    img = Image.open(io.BytesIO(file_bytes)).convert("RGB").resize((IMG_SIZE, IMG_SIZE))
    x_single = np.array(img, dtype=np.float32)
    x_single = np.expand_dims(x_single, axis=0)

    # Predicción con ambos modelos
    probs_fusion = model.predict(x_single, verbose=0)[0]
    probs_seq = model_seq.predict(x_single, verbose=0)[0]

    pred_idx_fusion = int(np.argmax(probs_fusion))
    pred_idx_seq = int(np.argmax(probs_seq))

    # Visualización comparativa
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # Imagen original
    axes[0].imshow(img)
    axes[0].axis('off')
    axes[0].set_title('Imagen Original', fontweight='bold')

    # Predicción Fusión
    axes[1].imshow(img)
    axes[1].axis('off')
    axes[1].set_title(f'Fusión (Paralelo)\n{label_names[pred_idx_fusion]}\np={probs_fusion[pred_idx_fusion]:.3f}',
                     fontweight='bold', color='blue')

    # Predicción Secuencial
    axes[2].imshow(img)
    axes[2].axis('off')
    axes[2].set_title(f'Secuencial\n{label_names[pred_idx_seq]}\np={probs_seq[pred_idx_seq]:.3f}',
                     fontweight='bold', color='red')

    plt.tight_layout()
    plt.show()

    # Mostrar top-3 predicciones para cada modelo
    print(f"\nImagen: {fname}")
    print("\nTop-3 Predicciones - Modelo Fusión:")
    top3_fusion = np.argsort(probs_fusion)[-3:][::-1]
    for i, idx in enumerate(top3_fusion, 1):
        print(f"  {i}. {label_names[idx]}: {probs_fusion[idx]:.4f}")

    print("\nTop-3 Predicciones - Modelo Secuencial:")
    top3_seq = np.argsort(probs_seq)[-3:][::-1]
    for i, idx in enumerate(top3_seq, 1):
        print(f"  {i}. {label_names[idx]}: {probs_seq[idx]:.4f}")